{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample:  Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from varclushi import VarClusHi \n",
    "import scikitplot as skplt\n",
    "import time\n",
    "\n",
    "from scipy.stats import uniform as flt\n",
    "from scipy.stats import randint as itr\n",
    "\n",
    "\n",
    "#Algorithm\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, KFold , cross_val_score, StratifiedKFold, cross_validate\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import  roc_auc_score, brier_score_loss, precision_score, recall_score, roc_curve\n",
    "from sklearn.calibration import calibration_curve\n",
    "from matplotlib import pyplot\n",
    "import pickle\n",
    "import lightgbm as lgb\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "                                                                                                        \n",
    "#Explainer\n",
    "\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data):\n",
    "    \"\"\"Used to import dataset\n",
    "    \n",
    "    Returns: Input Datframe\n",
    "    \"\"\"\n",
    "    return pd.read_sas(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preparation(data_in, data_index, remove_list, target):\n",
    "    \n",
    "    \"\"\"Prepare dataset for feature generation\n",
    "    \n",
    "    Steps:\n",
    "    1. Set index to unique ID in column\n",
    "    2. Drop unnecessary columns from source\n",
    "    4. Creates Feature Dataframe and Target Variable\n",
    "    \n",
    "     Args:\n",
    " \n",
    "    data_in: input data\n",
    "    index: input unique ID in data\n",
    "    list: list of columns to drop\n",
    "    y: target variable\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    tuple containing 0: dataframe , 1:target\n",
    "    \"\"\"\n",
    "  \n",
    "    data_ft = data_in.set_index(data_in[data_index], inplace = True)\n",
    "    data_ft = data_in.drop(columns=remove_list)\n",
    "    target =  data_in[target]\n",
    "\n",
    "    return data_ft, target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Model: Train and Test Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_partition(df_features, target, seed=123, prop=0.3):\n",
    "    \"\"\"Define Train and Test Set\n",
    "    \n",
    "    Args:\n",
    "    \n",
    "    1. df_features: dataframe of features\n",
    "    2. Target: Target Series\n",
    "    3. Seed: Random Seed default values\n",
    "    4. Prop: Test proportion\n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "    Tuple of Train and Test Sets\n",
    "    \"\"\"\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(df_features, target, stratify = target,\n",
    "                                                       random_state=seed, test_size=prop)\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_generation(df_features, target, corr_lmt = 0.9 ,eigval=1, n_clus=None):\n",
    "    \n",
    "    \"\"\"Apply Feature Selection \n",
    "    \n",
    "    1. Imputes NaN in Dataset\n",
    "    2. Remove features with Constant variance\n",
    "    3. Shortlists based on Correlation\n",
    "    4. Performs Variable Clustering using VarclusHi function\n",
    "    \n",
    "    Args:\n",
    "    \n",
    "    1. train_set: dataframe of features in training data\n",
    "    2. train_resp: target variable\n",
    "    3. corr_lmt : max correlation to consider on shotlist. Default is 0.9\n",
    "    4. eigval : max eigenvalue when doing clustering. Default is 1\n",
    "    5. n_clus : Clusters to be considered. Default value is none - builds all possible clusters\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "\n",
    "    Tuple of Shortlisted dataset, shortlisted variables\n",
    "    \"\"\"\n",
    "    \n",
    "    #Impute\n",
    "    df_features[df_features.isnull()] = 0\n",
    "    \n",
    "    #Remove Constant\n",
    "    constant_filter = VarianceThreshold(threshold = 0)\n",
    "    constant_filter.fit(df_features)\n",
    "    nonconstant = df_features.columns[constant_filter.get_support()].tolist()\n",
    "    df_features = df_features[nonconstant]\n",
    "    \n",
    "    #2 Remove Correlated variables\n",
    "    for_corr =[df_features, target]\n",
    "    for_corr = pd.concat((df_features, target), axis=1, join='inner')\n",
    "    corr = abs(for_corr.corr().iloc[:,-1])\n",
    "    corr = corr[(corr < corr_lmt)]\n",
    "    corr_slist = corr.index.tolist()\n",
    "    df_features = df_features[corr_slist]\n",
    "    \n",
    "    #3 Variable Clustering using VarClusHi\n",
    "    \n",
    "    cluster = VarClusHi(df_features, maxeigval2 = eigval, maxclus = n_clus)\n",
    "    cluster.varclus()\n",
    "    # Get top variables per cluster\n",
    "    list1 = cluster.rsquare.loc[cluster.rsquare.groupby([\"Cluster\"])['RS_Ratio'].idxmin()]\n",
    "    list1 = list1['Variable'].tolist()\n",
    "    df_features = df_features[list1]\n",
    "    \n",
    "    \n",
    "    return df_features, list1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_selection(x_train, y_train, x_test, y_test):\n",
    "    \"\"\"Perform Classification Model Selection\n",
    "    \n",
    "    Args:\n",
    "    \n",
    "    1. x_train = training data feature\n",
    "    2. y_train = training data label\n",
    "    3. x_test = test data feature\n",
    "    4. y_test = test data label\n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "    Prints model scoring for model selection\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    pipe_lr = Pipeline([('scl', StandardScaler()),\n",
    "                    ('clf', LogisticRegression(random_state=123, solver = 'liblinear' ))])\n",
    "\n",
    "    pipe_rf = Pipeline([('classifier', RandomForestClassifier(random_state=123 , n_estimators = 1000))])\n",
    "\n",
    "\n",
    "    pipe_lgb = Pipeline([('lgb' , lgb.LGBMClassifier())])\n",
    "\n",
    "\n",
    "    pipe_rlgb = Pipeline([('lgb' , lgb.LGBMClassifier())])\n",
    "\n",
    "    cv_params = {'lgb__learning_rate': flt(0.001, 0.2),\n",
    "             'lgb__max_depth': [3, 10],\n",
    "             'lgb__min_data_in_leaf': [20, 100],\n",
    "             'lgb__colsample_by_tree':flt(0.5,0.9),\n",
    "             'lgb__min_child_weight' :[1,3],\n",
    "             'lgb__bagging_fraction' :flt(0, 1)\n",
    "             }\n",
    "\n",
    "\n",
    "    rs_pipe_lgb = RandomizedSearchCV(estimator=pipe_rlgb,\n",
    "                                 param_distributions=cv_params,\n",
    "                                 scoring='roc_auc',\n",
    "                                 n_iter =10,\n",
    "                                 cv=10,\n",
    "                                 random_state=123)\n",
    "\n",
    "    pipelines = [pipe_lr, pipe_rf, pipe_lgb, rs_pipe_lgb]\n",
    "\n",
    "\n",
    "    start_time = time.time()\n",
    "    params =[]\n",
    "    for p in pipelines:\n",
    "        params =  p.fit(x_train, y_train)\n",
    "        \n",
    "        print('Fit time: %s' % (time.time() - start_time))\n",
    "        print(\"model score: %.3f\" % p.score(x_test[shortlist], y_test))\n",
    "                                        \n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit(x_train, y_train, x_test, y_test):\n",
    "    \"\"\"Fits chosen model in dataset\n",
    "    \n",
    "    Args:\n",
    "    \n",
    "    1. x_train = training data feature\n",
    "    2. y_train = training data label\n",
    "    3. x_test = test data feature\n",
    "    4. y_test = test data label\n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "    1. Fitted Model\n",
    "    2. Predicted Group\n",
    "    3. Predicted Probability\n",
    "    4. Probability Cutoff for Model Selection\n",
    "    5. Model Performance Metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    #Apply Transformation to x_test\n",
    "    \n",
    "    x_test[x_test.isnull()] = 0\n",
    "    \n",
    "    #Raw Scores\n",
    "    model = clf.fit(x_train, y_train\n",
    "                   ,early_stopping_rounds =100, verbose=False, eval_metric = 'logloss'\n",
    "                   ,eval_set = (x_test, y_test))\n",
    "    \n",
    "    p_raw = model.predict_proba(x_train)\n",
    "    \n",
    "    cutoff = np.around(np.percentile(p_raw[:,1], np.arange(0, 100, 10)), decimals = 7)\n",
    "    \n",
    "    #Predicted Group\n",
    "    p_grp = model.predict(x_test)\n",
    "    metrics        = {\"ROC\" : roc_auc_score(y_test, p_grp),\n",
    "                      \"Precision\" : precision_score(y_test, p_grp),\n",
    "                      \"Recall\": recall_score(y_test, p_grp)}\n",
    "   \n",
    "    #Save Model\n",
    "    \n",
    "    pickle.dump(model, open(\"lapse_model_mod.p\" , \"wb\"))\n",
    "\n",
    "    return model, p_grp, p_raw, cutoff, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_prediction(df, target, fitted_model):\n",
    "    \n",
    "    \"\"\"Evaluates model on Validation Set\n",
    "    \n",
    "    Args:\n",
    "    \n",
    "    1. df = validation set\n",
    "    2. target = response in validation set\n",
    "    3. model = fitted model\n",
    "\n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "    1. test data with predicted prob [p_1], decile score [decile] and original target\n",
    "    2. test data without original target\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    model = pickle.load(open(fitted_model , \"rb\"))\n",
    "    df['p_1'] = model.predict_proba(df)[:,1]\n",
    "    \n",
    "    conditions = [\n",
    "    (df['p_1'] <   0.0339419),\n",
    "    (df['p_1'] >=  0.0339419) & (df['p_1'] < 0.0411623),\n",
    "    (df['p_1'] >=  0.0411623) & (df['p_1'] < 0.0544696),\n",
    "    (df['p_1'] >=  0.0544696) & (df['p_1'] < 0.0794567),\n",
    "    (df['p_1'] >=  0.0794567) & (df['p_1'] < 0.1010139),\n",
    "    (df['p_1'] >=  0.1010139) & (df['p_1'] < 0.1374370),\n",
    "    (df['p_1'] >=  0.1374370) & (df['p_1'] < 0.1973212),\n",
    "    (df['p_1'] >=  0.1973212) & (df['p_1'] < 0.3045569),\n",
    "    (df['p_1'] >=  0.3045569) & (df['p_1'] < 0.6198479),\n",
    "    (df['p_1'] >=  0.6198479)]\n",
    "    choices = [10,9,8,7,6,5,4,3,2,1]\n",
    "\n",
    "    df['decile'] = np.select(conditions, choices, default='null').astype(int)\n",
    "   \n",
    "    val_list = [df , target]\n",
    "    validation_sets = val_list[0].join(val_list[1])\n",
    "    \n",
    "    return validation_sets, df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reports Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_report(data, y):\n",
    "    \"\"\"Generates Decile Analysis\n",
    "    \n",
    "    Args:\n",
    "    \n",
    "    1. data = data for decile analysis\n",
    "    2. y = target variable\n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "    1. decile analysis\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    data['nonresp'] = 1-data[y]\n",
    "    \n",
    "    deciles = pd.pivot_table(data=data,index=['decile'],\n",
    "                             values=[y,'nonresp'],\n",
    "                             aggfunc={y:[np.sum],\n",
    "                                     'nonresp':[np.sum]})\n",
    "    \n",
    "    deciles.to_csv(r'C:\\Users\\martken\\Documents\\sample.csv')\n",
    "    \n",
    "    return deciles"
   ]
  }
